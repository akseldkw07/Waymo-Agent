\documentclass[12pt]{article}

% \newcommand{\duedate}{10/09/2025}
% \newcommand{\assignment}{RL Project Proposal} % Change to "Problem Set X"

% % Change the following to your name and UNI.
% \newcommand{\name}{Aksel Kretsinger-Walters, adk2164}
% \newcommand{\email}{adk2164@columbia.edu}

% % NOTE: Defining collaborators is optional; to not list collaborators, comment out the
% % line below. Maximum of two collaborators per problem set.
\newcommand{\collaborators}{Aksel Kretsinger-Walters (\texttt{adk2164}), Alena Chan
(\texttt{ac5477}), Andrey Aksyutkin (\texttt{aa5499}), Blake Sisson (\texttt{mbs2246})}
% No collaborators on PS 0

\makeatletter
\def\input@path{{../}{../../}{../../../}} % add as many parents as you need
\makeatother
\input{pset_template.tex} %% DO NOT CHANGE THIS LINE

% Override the template margins to be less than 1 inch
% Load geometry after the template so it takes precedence.
\usepackage[margin=0.5in]{geometry}

\title{Waymo Fleet Profitability Optimizer}
\author{
		Aksel Kretsinger-Walters \and
		Alena Chan \and
		Andrey Aksyutkin \and
		Blake Sisson \footnote{Collaborator(s): \collaborators}
}
\date{}
\begin{document}
\maketitle

\subsection*{Problem Statement}
One of the most promising and revolutionary applications of reinforcement learning is in
the domain of autonomous robots, specifically self-driving cars. There are many challenges
in this domain: intellectual, ethical, technical, and more. For our project, we've decided
to narrow our focus to the specific problem of optimizing the profitability of a fleet of
self-driving cars.

Monitoring, maintaining, and optimizing a large fleet of self driving cars is a complex
problem, and one can quickly think of many dimensions that the problem takes on.
Predicting demand, scheduling maintenance, recharging vehicles, setting competitive
prices, maximizing coverage, minimizing wait times, and more are all separately non-trivial
problems. Jointly optimizing across all of these dimensions and adapting to distribution shifts
is an even more challenging problem, and the interactive nature of the problem makes it a natural
fit for reinforcement learning and agentic approaches.

We plan to simulate a fleet of self-driving cars as a Markov Decision Process (MDP), and
develop reinforcement learning algorithms to optimize the fleet's operations and profitability.

\subsection*{Interest and Relevance}
This is an area of active research and development, with many companies investing heavily in
self-driving technology. For this technology to reach the market, it is absolutely
critical to resolve the safety and reliability challenges that currently exist; however, the
economic viability must also be solved for self-driving to reach its full potential.

For the purposes of this course, we think that the interactive nature of the state with its
ecosystem, the high dimensionality of the state and action spaces, the data and research publicly
available and the possibility of performing far better than a heuristic algorithm make the
project a good fit for our semester project.

\begin{thebibliography}{9}

		\bibitem{lehd} U.S. Census Bureau. "LEHD Origin-Destination Employment Statistics
		(LODES)." \url{https://lehd.ces.census.gov/data/}
		\bibitem{suttonbarto} Sutton, R. S., \& Barto, A. G. "Reinforcement Learning: An
		Introduction." MIT Press, 2018.
		\bibitem{waymoopen} Waymo. "Waymo Open Dataset." \url{https://waymo.com/open/}
		\bibitem{citibike_rl} Xiao, I. "Reinforcement Learning Project: CitiBike."
		\url{https://github.com/ianxxiao/reinforcement_learning_project/blob/master/Reports/Presentation_RL_citiBike_20180514.pdf}
		\bibitem{ridesharing_survey} Li, J., Li, X., \& Wang, F. "Reinforcement Learning for
		Ridesharing: An Extended Survey." arXiv preprint arXiv:2102.11896, 2021.
\end{thebibliography}
\end{document}
